# YOLOv5 🚀 by Ultralytics, GPL-3.0 license
#yaml是一种适用于所有编程语言的人性化训练序列化语言
#包括yaml数据的定义和在其它程序中如何使用
# Parameters
#2参数配置
nc: 80  # number of classes
depth_multiple: 0.33  # model depth multiple模型层数因子，控制模型的深度，BottleneckCSP个数
width_multiple: 0.50  # layer channel multiple模型通道数因子，控制conv通道channel个数
#3先验框配置
#yolov5使用k-means聚类法来初始化了9个anchors，下面9个是coco数据集上的
anchors:
  - [10,13, 16,30, 33,23]  # P3/8，下采样小，感受野小，，anchor就小
  - [30,61, 62,45, 59,119]  # P4/16
  - [116,90, 156,198, 373,326]  # P5/32

# YOLOv5 v6.0 backbone
backbone:
  # [from, number, module, args]
  '''
  from:表示当前模块的输入来自哪一层的输出，-1表示将上一层输出当做自己的输入
  number:表示当前模块的重复次数，还与depth_multiple共同决定
  module:表示该层模块的名称，这些模块写在common.py中,进行模块化的搭建网络
  args:表示类的初始化参数，用于解析作为moudle的传入参数'''
    #channel=64,kernel_size=6,padding=2,stride=2,输出图片320*320*64
  [[-1, 1, Conv, [64, 6, 2, 2]],  # 0-P1/2#该层为第0层，输出后变成原图的1/2
   #channel=128,kernel_size=3,stride=2,输出160*160*128
   [-1, 1, Conv, [128, 3, 2]],  # 1-P2/4
   #channel=128,c3层，输出160*160*128
   [-1, 3, C3, [128]],
   #channel=256,kernel_size=3,stride=2,输出80*80*256
   [-1, 1, Conv, [256, 3, 2]],  # 3-P3/8
   [-1, 6, C3, [256]],#第四层输出
   [-1, 1, Conv, [512, 3, 2]],  # 5-P4/16
   [-1, 9, C3, [512]],#第六层输出
   [-1, 1, Conv, [1024, 3, 2]],  # 7-P5/32
   #此时图片变成了20*20*1024
   [-1, 3, C3, [1024]],
   #对不同尺度的特征进行融合，该层网络层名字是SPPF,channel=1024,kernel_size=5
   [-1, 1, SPPF, [1024, 5]],  # 9
  ]
#~~~~到第九层为止，这个部分会形成三个接口
#第四层输出：80*80*256
#第六层输出：40*40*512
#第九层输出：20*20*1024

# YOLOv5 v6.0 head
#Head包括Neck和Detect两部分，Neck采用了FPN+PAN结构
head:
##~~前两个阶段是向上concat
  [[-1, 1, Conv, [512, 1, 1]],#10 输出20*20*512
   #nn.upsample不改变channel但是会把图片的宽和高都变成2倍
   [-1, 1, nn.Upsample, [None, 2, 'nearest']],#变成40*40*512
   #[-1,6]输入是上一层和第六层的输出，concat层参数1，拼接维度是1
   [[-1, 6], 1, Concat, [1]],  # cat backbone P4，输出图片是40*40*1024
   #变成40*40*512
   [-1, 3, C3, [512, False]],  # 13,512通道，False表示没有残差模块
   #第14层，channel=256,kernel_size=1,stride=1,输出40*40*256
   [-1, 1, Conv, [256, 1, 1]],
   #size=None,scale_factor=2(输出尺寸是输入尺寸的倍数)
   [-1, 1, nn.Upsample, [None, 2, 'nearest']],#输出是80*80*256
   #第16层，上一层和第四层输出进行特征融合，得到80*80*512
   [[-1, 4], 1, Concat, [1]],  # cat backbone P3
   #第17层，卷积，得到80*80*256
   [-1, 3, C3, [256, False]],  # 17 (P3/8-small)


##~~后面的阶段是向下concat
   #输出40*40*256
   [-1, 1, Conv, [256, 3, 2]],
   #第19层，上一层和14层融合，拼接成40*40*512
   [[-1, 14], 1, Concat, [1]],  # cat head P4
   #第20层，输出40*40*512
   [-1, 3, C3, [512, False]],  # 20 (P4/16-medium)
   #第21层，输出图片20*20*512
   [-1, 1, Conv, [512, 3, 2]],
   #和第十层进行拼接，变成20*20*1024
   [[-1, 10], 1, Concat, [1]],  # cat head P5
   #第23层，C3处理，输出20*20*1024
   [-1, 3, C3, [1024, False]],  # 23 (P5/32-large)
   #第24层，Detect层，Detect是网络层名字
   [[17, 20, 23], 1, Detect, [nc, anchors]],  # Detect(P3, P4, P5)
  ]
